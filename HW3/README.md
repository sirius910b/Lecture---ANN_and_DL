# 인공신경망과 딥러닝 - 과제3 - Language Modeling



# 1. dataset.py 파일 설명
이 파일은 셰익스피어 데이터셋을 처리하여 모델에 입력할 데이터셋을 생성하는 코드입니다. PyTorch의 Dataset 클래스를 상속받아 커스텀 데이터셋 클래스를 만듭니다.

주요 내용
클래스 정의:

Shakespeare 클래스는 Dataset 클래스를 상속받아 구현되었습니다.
__init__ 메서드:

input_file 경로를 받아 파일을 열고, 텍스트를 읽어옵니다.
텍스트에 등장하는 모든 문자를 정렬된 집합으로 만들고, 각 문자를 인덱스에 매핑하는 딕셔너리(char2idx)와 인덱스를 문자에 매핑하는 딕셔너리(idx2char)를 생성합니다.
텍스트를 문자 인덱스의 리스트로 변환하여 text_as_int에 저장합니다.
시퀀스 길이를 30으로 설정합니다.
__len__ 메서드:

데이터셋의 길이를 반환합니다. 이는 텍스트를 시퀀스 길이로 나눈 값입니다.
__getitem__ 메서드:

주어진 인덱스에서 시작하는 시퀀스와 타깃 시퀀스를 반환합니다.
입력 시퀀스는 chunk[:-1], 타깃 시퀀스는 chunk[1:]으로 설정됩니다.
테스트 코드:

클래스의 인스턴스를 생성하고, 데이터셋의 길이를 출력하며, 첫 세 개의 입력 시퀀스와 타깃 시퀀스를 출력합니다.



# 2. model.py 파일 설명
이 파일은 문자 단위 언어 모델을 구현한 코드입니다. RNN과 LSTM 두 가지 모델을 정의하고 있습니다. PyTorch의 nn.Module을 상속받아 두 개의 클래스를 구현합니다.

주요 내용
CharRNN 클래스:

__init__: 어휘 크기(vocab_size), 은닉층 크기(hidden_size), 레이어 수(num_layers), 드롭아웃 확률(dropout)을 인자로 받습니다.
nn.Embedding을 사용하여 임베딩 레이어를 정의합니다.
nn.RNN을 사용하여 순환 신경망 레이어를 정의합니다.
nn.Linear을 사용하여 최종 선형 레이어를 정의합니다.
forward: 입력(input)과 은닉 상태(hidden)를 받아 임베딩, RNN, 그리고 선형 레이어를 통과시킵니다.
임베딩된 입력을 RNN에 전달하고, 출력을 선형 레이어를 통해 변환합니다.
init_hidden: 주어진 배치 크기(batch_size)에 대해 초기 은닉 상태를 반환합니다.
CharLSTM 클래스:

__init__: CharRNN과 유사하지만 LSTM 레이어를 사용합니다.
nn.LSTM을 사용하여 LSTM 레이어를 정의합니다.
forward: 입력(input)과 은닉 상태(hidden)를 받아 임베딩, LSTM, 그리고 선형 레이어를 통과시킵니다.
임베딩된 입력을 LSTM에 전달하고, 출력을 선형 레이어를 통해 변환합니다.
init_hidden: 주어진 배치 크기(batch_size)에 대해 초기 은닉 상태와 셀 상태를 반환합니다.


# 3. main.py 파일 설명
이 파일은 문자 단위 언어 모델을 훈련 및 검증하고, 결과를 시각화하는 코드입니다.

주요 내용
필요한 라이브러리와 모듈 임포트:

PyTorch, NumPy, tqdm, matplotlib, dataset, model 등을 임포트합니다.
train 함수:

모델을 훈련하는 함수입니다.
입력과 타깃 데이터를 장치로 이동시키고, 은닉 상태를 초기화합니다.
모델의 출력을 계산하고 손실을 구한 후 역전파를 통해 모델을 업데이트합니다.
평균 훈련 손실 값을 반환합니다.
validate 함수:

모델을 검증하는 함수입니다.
입력과 타깃 데이터를 장치로 이동시키고, 은닉 상태를 초기화합니다.
모델의 출력을 계산하고 손실을 구합니다.
평균 검증 손실 값을 반환합니다.
main 함수:

데이터셋을 불러오고, 훈련 및 검증 데이터셋으로 분할합니다.
데이터 로더를 생성합니다.
모델을 정의하고, 손실 함수와 옵티마이저를 설정합니다.
훈련 및 검증 손실 값을 저장하고, 각 에포크마다 출력합니다.
훈련된 모델의 가중치를 저장합니다.
훈련 및 검증 손실 값을 그래프로 시각화하여 저장하고 표시합니다.
스크립트 실행:

model_type을 설정하고, main 함수를 호출하여 모델을 훈련합니다.

### 1) RNN Model Loss
![LSTM_loss_plot](https://github.com/sirius910b/Lecture---ANN_and_DL/assets/151756312/945f6ddd-8a3d-4cb8-8141-e3fb49b9f4b4)


### 2) LSTM Model Loss
![RNN_loss_plot](https://github.com/sirius910b/Lecture---ANN_and_DL/assets/151756312/88192d75-9ca1-4529-a4ac-2fc96b7f3b8c)




# 4. generate.py 파일 설명
이 파일은 훈련된 RNN 또는 LSTM 모델을 사용하여 문자 단위 텍스트를 생성하는 코드입니다.

주요 내용
필요한 라이브러리와 모듈 임포트:

PyTorch, torch.nn.functional 및 model 모듈에서 CharRNN과 CharLSTM을 임포트합니다.
generate 함수:

Args:
model: 훈련된 모델
seed_characters: 시드 문자들
temperature: 온도 파라미터 T
char2idx: 문자에서 인덱스로 매핑하는 딕셔너리
idx2char: 인덱스에서 문자로 매핑하는 딕셔너리
length: 생성할 문자 수
Returns:
생성된 문자 시퀀스
동작:
모델을 평가 모드로 설정하고, 장치에 할당합니다.
초기 은닉 상태를 설정합니다. LSTM의 경우 은닉 상태와 셀 상태 모두 설정합니다.
시드 문자를 인덱스 시퀀스로 변환합니다.
지정된 길이만큼 문자를 생성합니다. 각 스텝에서 모델의 출력을 소프트맥스 함수와 온도를 적용하여 확률 분포로 변환하고, 새로운 문자를 샘플링하여 시퀀스에 추가합니다.
메인 코드 블록:

셰익스피어 데이터셋을 불러옵니다.
model_type 변수를 사용하여 RNN 또는 LSTM 모델을 선택하고, 저장된 가중치를 로드합니다.
시드 문자와 온도를 설정하여 텍스트를 생성합니다.




